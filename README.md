ğŸ“ NLP Project â€“ Classification de commentaires selon leur toxicitÃ©

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de mon apprentissage du traitement automatique du langage naturel (NLP) et de la classification supervisÃ©e.
Lâ€™objectif Ã©tait de construire un pipeline complet allant du nettoyage des textes Ã  la modÃ©lisation, puis de comparer diffÃ©rentes approches classiques du machine learning.

ğŸ¯ Objectif

Classer automatiquement des commentaires en ligne selon plusieurs types de toxicitÃ© (multi-label) :
toxic
severe_toxic
obscene
threat
insult
identity_hate

ğŸ—ƒ DonnÃ©es

Jeu de donnÃ©es : Toxic Comment Classification Challenge â€“ Kaggle
train.csv : ~160 000 commentaires avec labels (multi-label)
test.csv : ~150 000 commentaires sans labels

ğŸ”§ Pipeline de traitement
1. PrÃ©traitement des donnÃ©es

Nettoyage des textes (regex, suppression des liens, chiffres, caractÃ¨res spÃ©ciaux)
Tokenisation (RegexpTokenizer)
Analyse exploratoire : longueur des phrases, distribution des classes (dÃ©sÃ©quilibre fort)

2. Vectorisation

TF-IDF (TfidfVectorizer) appliquÃ© sur lâ€™ensemble des textes

3. ModÃ©lisation & ExpÃ©rimentations
   
Baseline
RÃ©gression logistique (un classifieur par label)
Gestion du dÃ©sÃ©quilibre
Application de SMOTE : nette amÃ©lioration du recall et du F1-score pour les classes minoritaires
ModÃ¨les testÃ©s
RÃ©gression logistique (avec et sans SMOTE)
Random Forest
XGBoost
RÃ©duction de dimensions (TruncatedSVD) : testÃ©e mais peu concluante (perte de recall)
Validation
DÃ©coupage train/validation avec stratification
Ã‰valuation via : accuracy, precision, recall, F1-score, et matrices de confusion

ğŸ“Š RÃ©sultats

RÃ©gression logistique (baseline) : bons rÃ©sultats globaux, mais recall limitÃ© sur les classes rares.
RÃ©gression logistique + SMOTE : amÃ©lioration claire du F1 sur les classes minoritaires.
Random Forest : prÃ©cision correcte, mais recall insuffisant.
XGBoost : performances comparables Ã  la rÃ©gression logistique, mais plus coÃ»teux en ressources.
TruncatedSVD : rÃ©duction de dimensions testÃ©e, mais perte dâ€™information sur ce type de donnÃ©es.

ğŸ‘‰ Conclusion : pour ce problÃ¨me, un modÃ¨le simple (rÃ©gression logistique + SMOTE) surpasse ou Ã©gale les modÃ¨les plus complexes.

âš™ï¸ Outils et bibliothÃ¨ques

Data science : pandas, numpy, matplotlib, seaborn
NLP & ML : nltk, scikit-learn, imblearn, xgboost
Divers : re (expressions rÃ©guliÃ¨res)

ğŸ§  Perspectives

Ce projet mâ€™a permis dâ€™explorer plusieurs points clÃ©s :
Importance de la gestion du dÃ©sÃ©quilibre des classes
Comparaison modÃ¨les simples vs. complexes
Limites de la rÃ©duction de dimensions pour du texte vectorisÃ©

Prochaines pistes :
Tester des modÃ¨les NLP avancÃ©s (Word2Vec, BERT, DistilBERT)
Explorer des approches deep learning (RNN, LSTM, transformers)

DÃ©velopper une petite interface web (Flask/Streamlit) pour tester les prÃ©dictions en direct

